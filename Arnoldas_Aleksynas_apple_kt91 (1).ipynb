{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "### Practical Session\n",
    "\n",
    "<br/> Prof. Dr. Georgios K. Ouzounis\n",
    "<br/> email: georgios.ouzounis@go.kauko.lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Data loading and pre-processing\n",
    "2. Building the RNN\n",
    "3. Train and deploy the RNN\n",
    "4. Improving the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.sapientrade.com/images/2017/02/14/AI-Machine-Learning-Trading-Benefits.jpg\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 10-year history of the Apple Stock prices predict the stock values for the period of the recent most month that are not included in the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not use the github, so i don't need to use github, to download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "We need 3 main libraries:\n",
    "\n",
    "- [Numpy](http://www.numpy.org): it is the fundamental package for scientific computing with Python. It contains among other things a powerful N-dimensional array object that can be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined.\n",
    "- [matplotlib](https://matplotlib.org):  it is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "- [pandas](https://pandas.pydata.org): is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library importation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset description: the open high, low and close values of the Google Stock from 2012 to 2016. [Relevant code here](https://github.com/pdway53/Predict_Google_Stock_Price_RNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset importation\n",
    "\n",
    "# loading contents of the file for July 1st 2009 - July 31st 2019 \n",
    "dataset_train = pd.read_csv('AAPL_10yrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-07-01</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>5.166429</td>\n",
       "      <td>5.090000</td>\n",
       "      <td>5.101071</td>\n",
       "      <td>4.408037</td>\n",
       "      <td>414178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-02</td>\n",
       "      <td>5.044643</td>\n",
       "      <td>5.101071</td>\n",
       "      <td>4.992500</td>\n",
       "      <td>5.000714</td>\n",
       "      <td>4.321311</td>\n",
       "      <td>370479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-07-06</td>\n",
       "      <td>4.953571</td>\n",
       "      <td>4.963929</td>\n",
       "      <td>4.866071</td>\n",
       "      <td>4.950357</td>\n",
       "      <td>4.277796</td>\n",
       "      <td>498688400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-07-07</td>\n",
       "      <td>4.945714</td>\n",
       "      <td>4.988572</td>\n",
       "      <td>4.827857</td>\n",
       "      <td>4.835714</td>\n",
       "      <td>4.178730</td>\n",
       "      <td>461596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-07-08</td>\n",
       "      <td>4.854286</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>4.800714</td>\n",
       "      <td>4.900714</td>\n",
       "      <td>4.234900</td>\n",
       "      <td>575929200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close     Volume\n",
       "0  2009-07-01  5.125000  5.166429  5.090000  5.101071   4.408037  414178800\n",
       "1  2009-07-02  5.044643  5.101071  4.992500  5.000714   4.321311  370479200\n",
       "2  2009-07-06  4.953571  4.963929  4.866071  4.950357   4.277796  498688400\n",
       "3  2009-07-07  4.945714  4.988572  4.827857  4.835714   4.178730  461596800\n",
       "4  2009-07-08  4.854286  4.930000  4.800714  4.900714   4.234900  575929200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a subtable of related openings\n",
    "# The .values option causes this vector to form a numpy array\n",
    "training_set = dataset_train.iloc[:, 1:2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.125   ],\n",
       "       [ 5.044643],\n",
       "       [ 4.953571],\n",
       "       ...,\n",
       "       [51.869999],\n",
       "       [52.115002],\n",
       "       [52.189999]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays do not support the view() and head() methods. [More on accessing the numpy data](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1qb64Qywa-VEv2CG6M6tF0zSouWZC7X-S\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Next we need to rescale our data to the range from 0 to 1. \n",
    "\n",
    "Feature scaling is essential as discussed if the Features lecture and needs to be applied to both the training and test sets.\n",
    "\n",
    "It is computed using the ScikitLearn library [MinMaxScaler()](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) which transforms the selected feature by scaling it to a given range. If more than one, this estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the feature\n",
    "\n",
    "# importing the MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scaler instance to rescale all data to the range of 0.0 to 1.0 \n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a certain training set of scaled values\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00512321],\n",
       "       [0.00360247],\n",
       "       [0.00187895],\n",
       "       ...,\n",
       "       [0.88976301],\n",
       "       [0.89439965],\n",
       "       [0.89581895]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the training set to dependent and independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1bckuLGZCeLUzNA-xJCGOODzC-4n2U-If\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 90 timesteps and 1 output\n",
    "\n",
    "# The 90 stock prices in the last 3 months before today\n",
    "X_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2537, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's stock price\n",
    "y_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from day 90, then going back 90 days \n",
    "for i in range(90, 2537): \n",
    "    # Number 0 defines column ID, which is the only column in this case    \n",
    "    # Putting the last 90 days values in one row of X_train\n",
    "    X_train.append(training_set_scaled[i-90:i, 0]) \n",
    "    y_train.append(training_set_scaled[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00512321, 0.00360247, 0.00187895, ..., 0.03509875, 0.0370453 ,\n",
       "        0.03817401],\n",
       "       [0.00360247, 0.00187895, 0.00173026, ..., 0.0370453 , 0.03817401,\n",
       "        0.03824837],\n",
       "       [0.00187895, 0.00173026, 0.        , ..., 0.03817401, 0.03824837,\n",
       "        0.04124254],\n",
       "       ...,\n",
       "       [0.79925521, 0.78922501, 0.8071563 , ..., 0.89439965, 0.89066196,\n",
       "        0.89643403],\n",
       "       [0.78922501, 0.8071563 , 0.83232624, ..., 0.89066196, 0.89643403,\n",
       "        0.88976301],\n",
       "       [0.8071563 , 0.83232624, 0.81420575, ..., 0.89643403, 0.88976301,\n",
       "        0.89439965]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Matrix\n",
    "\n",
    "We need to add a new matrix dimension to accommodate the indicator (predictor). \n",
    "\n",
    "NumPy matrices are tensors (3D) and essentially we need to specify that our matrix consists of **60 days** (dimension x) times **total days in data set** (dimension y) times **1 value per matrix cell (scalar)** (dimension z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.pixabay.com/photo/2015/03/22/17/34/cubic-684961_1280.jpg\" width=\"500\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to add the stock value of somebody else together with the the past 60 days of Google, we need to change the length of the 3 dimension to  2.  RNN training tables are 3D!!! Read: [Reshaping NumPy Array | Numpy Array Reshape Examples](https://backtobazics.com/python/python-reshaping-numpy-array-examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformating the data matrix, we retain the 2 original dimensions and adding a third one with the depth of 1\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN initialization\n",
    "\n",
    "- Import the sequential model from the Keras API;\n",
    "- Import the Dense layer template from the Keras API;\n",
    "- Import the LSTM model from the Keras API\n",
    "- Create an instance of the sequential model called regressor because we want to predict a continuous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN as an arrangement of layers\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add First Layer\n",
    "\n",
    "We first add an object of the LSTM class! \n",
    "\n",
    "- The first argument is the number of units or LSTM memory cells. Include many neurons to address the high dimensionality of the problem; say 50 neurons! \n",
    "- Second arg: return sequences = true; stacked LSTM !\n",
    "- Third arg: input 3D shape: observations vs time steps vs number of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape =  (X_train.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argument is the dropout rate to ignore in the layers (20%) \n",
    "# For example 100 units * 20% = 20 units will be dropped each time\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Layers\n",
    "\n",
    "We can add more LSTM layers but along with Dropout regularization to make sure we avoid overfitting! \n",
    "\n",
    "We don’t need to add the shape of the layer again because it is recognized automatically from the number of input units.\n",
    "\n",
    "The last layer does not return a sequence but connected directly to a fully connected output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# I removed the return_sequences message, because we no longer return an arrangement, but a value instead\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Output Layer & Compile\n",
    "\n",
    "The output has 1 dimension , i.e. one value to be predicted thus or output fully connected layer has dimensionality = 1.\n",
    "\n",
    "- **Optimizer**: rmsprop is recommended in the Keras documentation. The Adam optimizer is also a powerful choice.\n",
    "- **Loss function**: regression problems take the mean square error as most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the RNN to the Training set\n",
    "\n",
    "We now want to train our RNN using the data in our **Training Set X** and **predictors in y** (ground truth in this case). Parameters that can be specified are the:\n",
    "\n",
    "- **Batch size**:  update the cell weights not on every stock price on every batch_size values; \n",
    "- **Number of epochs**: how many iterations to be used, i.e. number of forward and backward propagations for the update of the weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 0.0177\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0033\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 0.0031\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0029\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0027\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0026\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0024\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0027\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0021\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0020\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.0022\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0020\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0018\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0016\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0016\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0017\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 0.0016\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0016\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0015\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0015\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0015\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 9s 119ms/step - loss: 0.0014\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0015\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 10s 129ms/step - loss: 0.0013\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 0.0013\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 10s 131ms/step - loss: 0.0011\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0012\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0013\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 0.0013\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.0012\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 9s 122ms/step - loss: 0.0010\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 9s 121ms/step - loss: 0.0011\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 9s 120ms/step - loss: 0.0012\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0010\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 9.6664e-04\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 0.0010\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 9s 118ms/step - loss: 0.0010\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 10s 133ms/step - loss: 0.0010\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 11s 143ms/step - loss: 9.0010e-04\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 9.3464e-04\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 12s 155ms/step - loss: 9.7121e-04\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 9s 123ms/step - loss: 8.7005e-04\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 9.0117e-04\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.9838e-04\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.8267e-04\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 0.0011\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 9.1571e-04\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.1498e-04\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 7.8202e-04\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 9s 117ms/step - loss: 7.9562e-04\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 9.2687e-04\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 7.6054e-04\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.2989e-04\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 7.4528e-04\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.8895e-04\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 6.9904e-04\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 9.6884e-04\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 8.4398e-04\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 7.2793e-04\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 8.9012e-04\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 7.5768e-04\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 9s 114ms/step - loss: 8.0567e-04\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.8514e-04\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.8983e-04\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 8.0439e-04\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 7.0432e-04\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 8.0666e-04\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 6.7680e-04\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 7.7508e-04\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 0.0010\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.2464e-04\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.1807e-04\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 6.9308e-04\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 6.5387e-04\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.4201e-04\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 7.2248e-04\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 8.0725e-04\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 6.6426e-04\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 7.3956e-04\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 6.5707e-04\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.1333e-04\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 6.8514e-04\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.1193e-04\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 7.3907e-04\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 9s 112ms/step - loss: 6.6434e-04\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 9s 115ms/step - loss: 7.6597e-04\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 9s 113ms/step - loss: 6.9055e-04\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 12s 158ms/step - loss: 7.0031e-04\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 7.2399e-04\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 7.2060e-04\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 10s 136ms/step - loss: 6.4156e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 9s 120ms/step - loss: 6.7411e-04\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 9s 116ms/step - loss: 6.8634e-04\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 10s 128ms/step - loss: 6.4713e-04\n",
      "Epoch 99/100\n",
      "42/77 [===============>..............] - ETA: 4s - loss: 7.0884e-04"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Predictions\n",
    "\n",
    "Create a data-frame by importing the Apple Stock Price Test set for August 2019 using pandas and make it a numpy array.\n",
    "\n",
    "There are 22 financial days in one month, weekends are excluded!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the real stock price for August 1st 2019 - August 31st 2019\n",
    "\n",
    "dataset_test = pd.read_csv('AAPL_test.csv')\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "real_stock_price.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the stock price value for each day in August 2019, we need the values in the last 90 days.\n",
    "\n",
    "To obtain this **history** we need to combine both the training and test sets in one.\n",
    "\n",
    "If we were to use the training_set and test_set we would need to use the scaler  but that would change the actual test values.  Thus concatenate the original data frames!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of the future\n",
    "\n",
    "# Axis = 0 means concatenate the lines (for example: vertical axis)\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_total.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The contrast in the length of the first two gives us the first day in July 2019, and we need to go back 90 days to get the necessary range\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 90:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did not use iloc from panda so lets rearrange the numpy array for compatibility, for example: all the values from input lines to be stacked in one column. The -1 means that the numpy has no knowledge of how the values were stored in lines. The 1 means I want to them in one column\n",
    "\n",
    "inputs = inputs.reshape(-1,1) \n",
    "\n",
    "# Applying the feature scaler\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each price in Jan. 2017 we need the **immediate 90 values** before it. \n",
    "2. We have 21 prices in August;\n",
    "3. We need a numpy 3D array of 90 prices (columns) times 21 days (rows) times 1 dependent variable \n",
    "4. We don’t need y_test. That is what we are trying to compute!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of the future\n",
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 90 from inputs are from training set, starting from 90 and getting the extra 22\n",
    "for i in range(90, 112): \n",
    "    X_test.append(inputs[i-90:i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 3D structure\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to inverse the scaling to get useful predicted stock price\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) \n",
    "predicted_stock_price.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the results by graph\n",
    "\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Apple Stock Price')\n",
    "\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Apple Stock Price')\n",
    "\n",
    "plt.title('Apple Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Apple Stock Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue line shows the trend of the stock for the month of August 2019. \n",
    "\n",
    "Some observations:\n",
    "- The prediction lags behind the actual price curve because the model cannot react to fast non-linear changes. Spikes are examples of fast non-linear changes\n",
    "- Model reacts pretty well to smooth changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE\n",
    "\n",
    "If we need to compute the RMSE for our Stock Price Prediction problem, we use the real stock price and predicted stock price as shown.\n",
    "\n",
    "Then consider dividing this RMSE by the range of the Apple Stock Price values of August 2019 to get a relative error, as opposed to an absolute error. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = math.sqrt( mean_squared_error( real_stock_price[0:22,:], predicted_stock_price))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data need to be placed in the same order/format  as in the case of the training/test sets.\n",
    "\n",
    "1. Getting more training data: we trained our model on the past 10 years of the  Apple Stock Price but it would be even better to train it on the past 10 years.\n",
    "\n",
    "2. Increasing the number of time steps: the model remembered the stock price from the 60 previous financial days to predict the stock price of the next day. That’s because we chose a number of 90 time steps. You could try to increase the number of time steps, by choosing for example 120 time steps (6 months).\n",
    "\n",
    "3. Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Apple, you could add this other stock price as a new indicator in the training data.\n",
    "\n",
    "4. Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.\n",
    "\n",
    "5. Adding more neurons in the LSTM layers: we highlighted the fact that we needed a high number of neurons in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurons in each of our 4 LSTM layers. You could try an architecture with even more neurons in each of the 4 (or more) LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the RNN\n",
    "\n",
    "Parameter Tuning on the RNN model: we are dealing with a Regression problem because we predict a continuous outcome.\n",
    "\n",
    "**Tip**: replace: scoring = 'accuracy' by scoring = 'neg_mean_squared_error' in the GridSearchCV class parameters as we did in the ANN case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
